{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chatbot-1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"10Phb2cye5ny","colab_type":"text"},"source":["# Building a Chabot with DeepNLP"]},{"cell_type":"markdown","metadata":{"id":"PvavZcatfVOp","colab_type":"text"},"source":["# Part-0 Required installations"]},{"cell_type":"code","metadata":{"id":"qdW5q0U3fR4w","colab_type":"code","colab":{}},"source":["!pip3 install tensorflow==1.0.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhGQQsOEgIpR","colab_type":"code","colab":{}},"source":["# Remove CUDA 9 completely\n","!apt-get --purge remove cuda nvidia* libnvidia-*\n","!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n","!apt-get remove cuda-*\n","!apt autoremove\n","!apt-get update"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSvqKjLWgNww","colab_type":"code","colab":{}},"source":["!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n","!dpkg -i --force-overwrite cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n","!apt-get update\n","!apt-get install cuda-8-0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SOaiGInfg-k","colab_type":"code","colab":{}},"source":["!wget http://archive.ubuntu.com/ubuntu/pool/main/m/mesa/libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb\n","!dpkg -i --force-overwrite libglx-mesa0_18.0.5-0ubuntu0~18.04.1_amd64.deb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9EtrkMcrNkN","colab_type":"code","colab":{}},"source":["!wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/nvidia-410_410.48-0ubuntu1_amd64.deb\n","!dpkg -i --force-overwrite nvidia-410_410.48-0ubuntu1_amd64.deb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yv4lOcwFrO-b","colab_type":"code","colab":{}},"source":["!apt --fix-broken install\n","!apt-get install cuda-8-0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMvZQN1srzoI","colab_type":"code","colab":{}},"source":["!nvcc --version"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BEQFgC4hsFDl","colab_type":"code","colab":{}},"source":["!pip install tensorflow-gpu==1.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1uq5It0MsHgY","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ej0J_Q9e5n2","colab_type":"text"},"source":["# Part-1 Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"B7yENlRve5nz","colab_type":"code","colab":{}},"source":["#Importing libraries\n","import numpy as np\n","# import tensorflow as tf\n","#to clean the text\n","import re\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qK97ZyENfB-E","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUscO-Z2e5n4","colab_type":"code","colab":{}},"source":["#Importing the dataset\n","lines = open('/content/gdrive/My Drive/deepnlp/movie_lines.txt', encoding = 'utf-8', errors = 'ignore').read().split('\\n')\n","conversations = open('/content/gdrive/My Drive/deepnlp/movie_conversations.txt', encoding = 'utf-8', errors = 'ignore').read().split('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P1PzvqgXe5n6","colab_type":"code","colab":{}},"source":["# Creating a dictionary that maps each line and its id\n","id2line = {}\n","for line in lines:\n","    _line = line.split(' +++$+++ ')\n","    if len(_line) == 5:\n","        id2line[_line[0]] = _line[4]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8mxan6N_e5n8","colab_type":"code","colab":{}},"source":["id2line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEh2-Zvoe5oB","colab_type":"code","colab":{}},"source":["conversations_ids = []\n","for conversation in conversations[:-1]:\n","    _conversation = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n","    conversations_ids.append(_conversation.split(','))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHc_Irgye5oF","colab_type":"code","colab":{}},"source":["conversations_ids"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPqTF2Uze5oI","colab_type":"code","colab":{}},"source":["# Getting seperately the Questions and Answers\n","questions = []\n","answers = []\n","for conversation in conversations_ids:\n","    for i in range(len(conversation)-1):\n","        questions.append(id2line[conversation[i]])\n","        answers.append(id2line[conversation[i+1]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZpyAjWobe5oL","colab_type":"code","colab":{}},"source":["questions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrwfIne4e5oO","colab_type":"code","colab":{}},"source":["answers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HCstC4-e5oR","colab_type":"code","colab":{}},"source":["# Doing a first cleaning of the text\n","def clean_text(text):\n","    text = text.lower()\n","    #remove apostrophes\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"what's\", \"what is\", text)\n","    text = re.sub(r\"where's\", \"where is\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"\\'d\", \" would\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"don't\", \"do not\", text)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"let's\", \"let us\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"[-()\\\"#/@;:<>{}+=~|.?,]\", \"\", text)\n","    return text\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCUyvVone5oT","colab_type":"code","colab":{}},"source":["# Cleaning the question\n","clean_questions = []\n","for question in questions:\n","    clean_questions.append(clean_text(question))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yt6a9T1Ce5oX","colab_type":"code","colab":{}},"source":["clean_questions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CogM73qye5ob","colab_type":"code","colab":{}},"source":["# Cleaning the answers\n","clean_answers = []\n","for answer in answers:\n","    clean_answers.append(clean_text(answer))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"22Vu-hOZe5oc","colab_type":"code","colab":{}},"source":["clean_answers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hi5hMlqye5og","colab_type":"code","colab":{}},"source":["#Creating a dictionary that maps each word to its number of occurances\n","word2count = {}\n","for question in clean_questions:\n","    for word in question.split():\n","        if word not in word2count:\n","            word2count[word] = 1\n","        else:\n","            word2count[word] += 1\n","\n","for answer in clean_answers:\n","    for word in answer.split():\n","        if word not in word2count:\n","            word2count[word] = 1\n","        else:\n","            word2count[word] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhZSXtoSe5on","colab_type":"code","colab":{}},"source":["word2count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TLyIl_9Pe5or","colab_type":"code","colab":{}},"source":["len(word2count)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSkLllmWe5ov","colab_type":"code","colab":{}},"source":["#Creating two dictionaries that map the questions words and the answers words to a unique integer\n","threshold = 20\n","questionswords2int = {}\n","word_number = 0\n","for word, count in word2count.items():\n","    if count >=threshold:\n","        questionswords2int[word] = word_number\n","        word_number += 1\n","        \n","answerswords2int = {}\n","word_number = 0\n","for word, count in word2count.items():\n","    if count >=threshold:\n","        answerswords2int[word] = word_number\n","        word_number += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxO8uO5fe5o2","colab_type":"code","colab":{}},"source":["questionswords2int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjV2S84ee5o8","colab_type":"code","colab":{}},"source":["answerswords2int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJYcZCa1e5pA","colab_type":"code","colab":{}},"source":["# Addding the last tokens to these two dictionarries\n","tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n","for token in tokens:\n","    questionswords2int[token] = len(questionswords2int) + 1\n","for token in tokens:\n","    answerswords2int[token] = len(answerswords2int) + 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"non-nn39e5pC","colab_type":"code","colab":{}},"source":["# Creating the inverse dictionary of the answerswords2int dictionary\n","answersints2word = {w_i: w for w, w_i in answerswords2int.items()}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsRJHCuSe5pD","colab_type":"code","colab":{}},"source":["answersints2word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbPrnzJde5pG","colab_type":"code","colab":{}},"source":["# Adding End of String token to the end of ever answer\n","for i in range(len(clean_answers)):\n","    clean_answers[i] += ' <EOS>'\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_F2yADTe5pI","colab_type":"code","colab":{}},"source":["clean_answers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rUYaoe8Ee5pM","colab_type":"code","colab":{}},"source":["# Translating all the questions ans the answers into integers\n","# and Replacing all the words that were filtered out by <OUT>\n","questions_to_int = []\n","for question in clean_questions:\n","    ints = []\n","    for word in question.split():\n","        if word not in questionswords2int:\n","            ints.append(questionswords2int['<OUT>'])\n","        else:\n","            ints.append(questionswords2int[word])\n","    questions_to_int.append(ints)\n","    \n","answers_to_int = []\n","for answer in clean_answers:\n","    ints = []\n","    for word in answer.split():\n","        if word not in answerswords2int:\n","            ints.append(answerswords2int['<OUT>'])\n","        else:\n","            ints.append(answerswords2int[word])\n","    answers_to_int.append(ints)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1xU5gxie5pN","colab_type":"code","colab":{}},"source":["questions_to_int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UP8c1QFJe5pR","colab_type":"code","colab":{}},"source":["answers_to_int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaXH33z2e5pT","colab_type":"code","colab":{}},"source":["# Sorting questions ans answers by the length of questions\n","sorted_clean_questions = []\n","sorted_clean_answers = []\n","for length in range(1, 25 + 1):\n","    for i in enumerate(questions_to_int):\n","        if len(i[1]) == length:\n","            sorted_clean_questions.append(questions_to_int[i[0]])\n","            sorted_clean_answers.append(answers_to_int[i[0]])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tYaXUtNe5pV","colab_type":"code","colab":{}},"source":["sorted_clean_questions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEPT6dRUe5pX","colab_type":"code","colab":{}},"source":["sorted_clean_answers"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kwyw_71ce5pa","colab_type":"text"},"source":["# PART-2 BUILDING SEQ2SEQ MODEL"]},{"cell_type":"code","metadata":{"id":"dKTFSotRe5pb","colab_type":"code","colab":{}},"source":["# Creating placeholders for the inputs and the targets \n","def model_inputs():\n","    inputs = tf.placeholder(tf.int32, [None, None], name = 'input')\n","    targets = tf.placeholder(tf.int32, [None, None], name = 'target')\n","    lr = tf.placeholder(tf.float32, name = 'learning_rate')\n","    keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n","    return inputs, targets, lr, keep_prob"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5id1TlTue5pc","colab_type":"code","colab":{}},"source":["# Preprocessing the targets \n","def preprocess_targets(targets, word2int, batch_size):\n","    left_side = tf.fill([batch_size, 1], word2int['<SOS>'])\n","    right_side = tf.strided_slice(targets, [0,0], [batch_size, -1], [1,1])\n","    preprocessed_targets = tf.concat([left_side, right_side], 1)\n","    return preprocessed_targets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_D11NPiYe5pd","colab_type":"code","colab":{}},"source":["# Creating the Encoder RNN Layer\n","def encoder_rnn(rnn_inputs, rnn_size, num_layers, keep_prob, sequence_length):\n","    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n","    lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\n","    encoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_dropout] * num_layers)\n","    encoder_output, encoder_state = tf.nn.bidirectional_dynamic_rnn(cell_fw = encoder_cell,\n","                                                                    cell_bw = encoder_cell,\n","                                                                    sequence_length = sequence_length,\n","                                                                    inputs = rnn_inputs,\n","                                                                    dtype = tf.float32)\n","    return encoder_state"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssSGjXuue5pg","colab_type":"code","colab":{}},"source":["# Decoding the training set \n","def decode_training_set(encoder_state, decoder_cell, decoder_embedded_input, sequence_length, decoding_scope, output_function, keep_prob, batch_size):\n","    attention_states = tf.zeros([batch_size, 1, decoder_cell.output_size])\n","    attention_keys, attention_values, attention_score_function, attention_construct_function = tf.contrib.seq2seq.prepare_attention(attention_states, attention_option = \"bahdanau\", num_units = decoder_cell.output_size)\n","    training_decoder_function = tf.contrib.seq2seq.attention_decoder_fn_train(encoder_state[0],\n","                                                                              attention_keys,\n","                                                                              attention_values,\n","                                                                              attention_score_function,\n","                                                                              attention_construct_function,\n","                                                                              name = \"attn_dec_train\")\n","    decoder_output, decoder_final_state, decoder_final_context_state = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,\n","                                                                                                              training_decoder_function,\n","                                                                                                              decoder_embedded_input,\n","                                                                                                              sequence_length,\n","                                                                                                              scope = decoding_scope)\n","    decoder_output_dropout = tf.nn.dropout(decoder_output, keep_prob)\n","    return output_function(decoder_output_dropout)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTmietcZe5pi","colab_type":"code","colab":{}},"source":["# Decoding the test/validation set\n","def decode_test_set(encoder_state, decoder_cell, decoder_embeddings_matrix, sos_id, eos_id, maximum_length, num_words, decoding_scope, output_function, keep_prob, batch_size):\n","    attention_states = tf.zeros([batch_size, 1, decoder_cell.output_size])\n","    attention_keys, attention_values, attention_score_function, attention_construct_function = tf.contrib.seq2seq.prepare_attention(attention_states, attention_option = \"bahdanau\", num_units = decoder_cell.output_size)\n","    test_decoder_function = tf.contrib.seq2seq.attention_decoder_fn_inference(output_function,\n","                                                                              encoder_state[0],\n","                                                                              attention_keys,\n","                                                                              attention_values,\n","                                                                              attention_score_function,\n","                                                                              attention_construct_function,\n","                                                                              decoder_embeddings_matrix,\n","                                                                              sos_id,\n","                                                                              eos_id,\n","                                                                              maximum_length,\n","                                                                              num_words,\n","                                                                              name = \"attn_dec_inf\")\n","    test_predictions, decoder_final_state, decoder_final_context_state = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,\n","                                                                                                                test_decoder_function,\n","                                                                                                                scope = decoding_scope)\n","    return test_predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iv33z3P1e5pk","colab_type":"code","colab":{}},"source":["# Creating the Decoder RNN\n","def decoder_rnn(decoder_embedded_input, decoder_embeddings_matrix, encoder_state, num_words, sequence_length, rnn_size, num_layers, word2int, keep_prob, batch_size):\n","    with tf.variable_scope(\"decoding\") as decoding_scope:\n","        lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n","        lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\n","        decoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_dropout] * num_layers)\n","        weights = tf.truncated_normal_initializer(stddev = 0.1)\n","        biases = tf.zeros_initializer()\n","        output_function = lambda x: tf.contrib.layers.fully_connected(x,\n","                                                                      num_words,\n","                                                                      None,\n","                                                                      scope = decoding_scope,\n","                                                                      weights_initializer = weights,\n","                                                                      biases_initializer = biases)\n","        training_predictions = decode_training_set(encoder_state,\n","                                                   decoder_cell,\n","                                                   decoder_embedded_input,\n","                                                   sequence_length,\n","                                                   decoding_scope,\n","                                                   output_function,\n","                                                   keep_prob,\n","                                                   batch_size)\n","        decoding_scope.reuse_variables()\n","        test_predictions = decode_test_set(encoder_state,\n","                                           decoder_cell,\n","                                           decoder_embeddings_matrix,\n","                                           word2int['<SOS>'],\n","                                           word2int['<EOS>'],\n","                                           sequence_length - 1,\n","                                           num_words,\n","                                           decoding_scope,\n","                                           output_function,\n","                                           keep_prob,\n","                                           batch_size)\n","    return training_predictions, test_predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLt8vRUbe5pn","colab_type":"code","colab":{}},"source":["# Building seq2seq model\n","def seq2seq_model(inputs, targets, keep_prob, batch_size, sequence_length, answers_num_words, questions_num_words, encoder_embedding_size, decoder_embedding_size, rnn_size, num_layers, questionswords2int):\n","    encoder_embedded_input = tf.contrib.layers.embed_sequence(inputs,\n","                                                              answers_num_words + 1,\n","                                                              encoder_embedding_size,\n","                                                              initializer = tf.random_uniform_initializer(0, 1))\n","    encoder_state = encoder_rnn(encoder_embedded_input, rnn_size, num_layers, keep_prob, sequence_length)\n","    preprocessed_targets = preprocess_targets(targets, questionswords2int, batch_size)\n","    decoder_embeddings_matrix = tf.Variable(tf.random_uniform([questions_num_words + 1, decoder_embedding_size], 0, 1))\n","    decoder_embedded_input = tf.nn.embedding_lookup(decoder_embeddings_matrix, preprocessed_targets)\n","    training_predictions, test_predictions = decoder_rnn(decoder_embedded_input,\n","                                                         decoder_embeddings_matrix,\n","                                                         encoder_state,\n","                                                         questions_num_words,\n","                                                         sequence_length,\n","                                                         rnn_size,\n","                                                         num_layers,\n","                                                         questionswords2int,\n","                                                         keep_prob,\n","                                                         batch_size)\n","    return training_predictions, test_predictions"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwT2QDR2e5pq","colab_type":"text"},"source":["# Part-3 Training the seq2seq model"]},{"cell_type":"code","metadata":{"id":"RpvTI4iye5pq","colab_type":"code","colab":{}},"source":["# Setting the Hyperparameters\n","epochs = 50\n","batch_size = 64\n","rnn_size = 512\n","num_layers = 3\n","encoding_embedding_size = 512\n","decoding_embedding_size = 512\n","learning_rate = 0.01\n","learning_rate_decay = 0.9\n","min_learning_rate = 0.0001\n","keep_probability = 0.5\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"al2_NC-fe5pt","colab_type":"code","colab":{}},"source":["# Defining a session\n","tf.reset_default_graph()\n","session = tf.InteractiveSession()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClU3xjjIe5pw","colab_type":"code","colab":{}},"source":["# Loading the model seq2seq\n","inputs, targets, lr, keep_prob = model_inputs()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYAVaKaqe5pz","colab_type":"code","colab":{}},"source":["# Setting the sequence length\n","sequence_length = tf.placeholder_with_default(25, None, name = 'sequence_length')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ya0-4T_Be5p2","colab_type":"code","colab":{}},"source":["# Getting the shape of the inputs tensor\n","input_shape = tf.shape(inputs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYmXoL7re5p6","colab_type":"code","colab":{}},"source":["# Getting the training and test predictions\n","training_predictions, test_predictions = seq2seq_model(tf.reverse(inputs, [-1]),\n","                                                       targets,\n","                                                       keep_prob,\n","                                                       batch_size,\n","                                                       sequence_length,\n","                                                       len(answerswords2int),\n","                                                       len(questionswords2int),\n","                                                       encoding_embedding_size,\n","                                                       decoding_embedding_size,\n","                                                       rnn_size,\n","                                                       num_layers,\n","                                                       questionswords2int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzSdwZBZe5p8","colab_type":"code","colab":{}},"source":["# Setting up the Loss Error, the Optimizer and Gradient Clipping\n","with tf.name_scope(\"optimization\"):\n","    loss_error = tf.contrib.seq2seq.sequence_loss(training_predictions,\n","                                                  targets,\n","                                                  tf.ones([input_shape[0], sequence_length]))\n","    optimizer = tf.train.AdamOptimizer(learning_rate)\n","    gradients = optimizer.compute_gradients(loss_error)\n","    clipped_gradients = [(tf.clip_by_value(grad_tensor, -5., 5.), grad_variable) for grad_tensor, grad_variable in gradients if grad_tensor is not None]\n","    optimizer_gradient_clipping = optimizer.apply_gradients(clipped_gradients)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3w1J4bCe5p-","colab_type":"code","colab":{}},"source":["# Padding the sequences with the <PAD> token\n","def apply_padding(batch_of_sequences, word2int):\n","    max_sequence_length = max([len(sequence) for sequence in batch_of_sequences])\n","    return [sequence + [word2int['<PAD>']] * (max_sequence_length - len(sequence)) for sequence in batch_of_sequences]\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5T5UOYl1e5qA","colab_type":"code","colab":{}},"source":["# Splitting the data into batches of questions and answers\n","def split_into_batches(questions, answers, batch_size):\n","    for batch_index in range(0, len(questions) // batch_size):\n","        start_index = batch_index * batch_size\n","        questions_in_batch = questions[start_index : start_index + batch_size]\n","        answers_in_batch = answers[start_index : start_index + batch_size]\n","        padded_questions_in_batch = np.array(apply_padding(questions_in_batch, questionswords2int))\n","        padded_answers_in_batch = np.array(apply_padding(answers_in_batch, answerswords2int))\n","        yield padded_questions_in_batch, padded_answers_in_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoGdHd99e5qD","colab_type":"code","colab":{}},"source":["# Splitting the questions and answers into training and validation sets\n","training_validation_split = int(len(sorted_clean_questions) * 0.15)\n","training_questions = sorted_clean_questions[training_validation_split:]\n","training_answers = sorted_clean_answers[training_validation_split:]\n","validation_questions = sorted_clean_questions[:training_validation_split]\n","validation_answers = sorted_clean_answers[:training_validation_split]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_tkvnYSe5qF","colab_type":"code","colab":{}},"source":["# Training\n","batch_index_check_training_loss = 100\n","batch_index_check_validation_loss = ((len(training_questions)) // batch_size // 2) - 1\n","total_training_loss_error = 0\n","list_validation_loss_error = []\n","early_stopping_check = 0\n","early_stopping_stop = 1000\n","checkpoint = \"/content/gdrive/My Drive/deepnlp/\" + \"chatbot_weights.ckpt\"\n","session.run(tf.global_variables_initializer())\n","for epoch in range(1, epochs + 1):\n","    for batch_index, (padded_questions_in_batch, padded_answers_in_batch) in enumerate(split_into_batches(training_questions, training_answers, batch_size)):\n","        starting_time = time.time()\n","        _, batch_training_loss_error = session.run([optimizer_gradient_clipping, loss_error], {inputs: padded_questions_in_batch,\n","                                                                                               targets: padded_answers_in_batch,\n","                                                                                               lr: learning_rate,\n","                                                                                               sequence_length: padded_answers_in_batch.shape[1],\n","                                                                                               keep_prob: keep_probability})\n","        total_training_loss_error += batch_training_loss_error\n","        ending_time = time.time()\n","        batch_time = ending_time - starting_time\n","        if batch_index % batch_index_check_training_loss == 0:\n","            print('Epoch: {:>3}/{}, Batch: {:>4}/{}, Training Loss Error: {:>6.3f}, Training Time on 100 Batches: {:d} seconds'.format(epoch,\n","                                                                                                                                       epochs,\n","                                                                                                                                       batch_index,\n","                                                                                                                                       len(training_questions) // batch_size,\n","                                                                                                                                       total_training_loss_error / batch_index_check_training_loss,\n","                                                                                                                                       int(batch_time * batch_index_check_training_loss)))\n","            total_training_loss_error = 0\n","        if batch_index % batch_index_check_validation_loss == 0 and batch_index > 0:\n","            total_validation_loss_error = 0\n","            starting_time = time.time()\n","            for batch_index_validation, (padded_questions_in_batch, padded_answers_in_batch) in enumerate(split_into_batches(validation_questions, validation_answers, batch_size)):\n","                batch_validation_loss_error = session.run(loss_error, {inputs: padded_questions_in_batch,\n","                                                                       targets: padded_answers_in_batch,\n","                                                                       lr: learning_rate,\n","                                                                       sequence_length: padded_answers_in_batch.shape[1],\n","                                                                       keep_prob: 1})\n","                total_validation_loss_error += batch_validation_loss_error\n","            ending_time = time.time()\n","            batch_time = ending_time - starting_time\n","            average_validation_loss_error = total_validation_loss_error / (len(validation_questions) / batch_size)\n","            print('Validation Loss Error: {:>6.3f}, Batch Validation Time: {:d} seconds'.format(average_validation_loss_error, int(batch_time)))\n","            learning_rate *= learning_rate_decay\n","            if learning_rate < min_learning_rate:\n","                learning_rate = min_learning_rate\n","            list_validation_loss_error.append(average_validation_loss_error)\n","            if average_validation_loss_error <= min(list_validation_loss_error):\n","                print('I speak better now!!')\n","                early_stopping_check = 0\n","                saver = tf.train.Saver()\n","                saver.save(session, checkpoint)\n","            else:\n","                print(\"Sorry I do not speak better, I need to practice more.\")\n","                early_stopping_check += 1\n","                if early_stopping_check == early_stopping_stop:\n","                    break\n","    if early_stopping_check == early_stopping_stop:\n","        print(\"My apologies, I cannot speak better anymore. This is the best I can do.\")\n","        break\n","print(\"Game Over\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKkAEuw0e5qH","colab_type":"code","colab":{}},"source":["# PART-4 TESTING THE SEQ2SEQ MODEL"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9yUauarce5qJ","colab_type":"code","colab":{}},"source":["# Loading the weights and Running the session\n","checkpoint = \"/content/gdrive/My Drive/deepnlp/\" + \"chatbot_weights.ckpt\"\n","session = tf.InteractiveSession()\n","session.run(tf.global_variables_initializer())\n","saver = tf.train.Saver()\n","saver.restore(session, checkpoint)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcVex1Ym7wdd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uK_-tzNe5qL","colab_type":"code","colab":{}},"source":["# Converting the questions from strings to lists of encoding integers\n","def convert_string2int(question, word2int):\n","    question = clean_text(question)\n","    return [word2int.get(word, word2int['<OUT>']) for word in question.split()]\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Pxvcb0qe5qO","colab_type":"code","colab":{}},"source":["# Setting up the chat\n","while(True):\n","    question = input(\"You: \")\n","    if question == 'Goodbye':\n","        break\n","    question = convert_string2int(question, questionswords2int)\n","    question = question + [questionswords2int['<PAD>']] * (20 - len(question))\n","    fake_batch = np.zeros((batch_size, 20))\n","    fake_batch[0] = question\n","    predicted_answer = session.run(test_predictions, {inputs: fake_batch, keep_prob: 0.5})[0]\n","    answer = ''\n","    for i in np.argmax(predicted_answer, 1):\n","        if answersints2word[i] == 'i':\n","            token = ' I'\n","        elif answersints2word[i] == '<EOS>':\n","            token = '.'\n","        elif answersints2word[i] == '<OUT>':\n","            token = 'out'\n","        else:\n","            token = ' ' + answersints2word[i]\n","        answer += token\n","        if token == '.':\n","            break\n","    print('ChatBot: ' + answer)"],"execution_count":0,"outputs":[]}]}